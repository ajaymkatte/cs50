#!/usr/bin/env python3
import sys
import os
import nltk
from helpers import get_user_timeline
from analyzer import Analyzer
from termcolor import colored

def main():

    if len(sys.argv) != 2:
        print("Usage: ./tweets @handle")
        exit(1)

    # absolute paths to lists
    positives = os.path.join(sys.path[0], "positive-words.txt")
    negatives = os.path.join(sys.path[0], "negative-words.txt")

    # instantiate analyzer
    analyzer = Analyzer(positives, negatives)

    tweets = (get_user_timeline(sys.argv[1], 50))

    # Break into strings
    for element in tweets:
        score = 0
        tokenizer = nltk.tokenize.TweetTokenizer()
        tokens = tokenizer.tokenize(element)
        for word in tokens:
            score += analyzer.analyze(word)
        if score > 0:
            print(colored(" {} {}".format(score, element), "green"))
        elif score < 0:
            print(colored("{} {}".format(score, element), "red"))
        else:
            print(colored(" {} {}".format(score, element), "yellow"))

if __name__ == "__main__":
    main()